import os
import time
import random
import base64
import json
import requests
from dotenv import load_dotenv
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
from selenium.common.exceptions import WebDriverException, TimeoutException
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from urllib.parse import urlparse
from webdriver_manager.chrome import ChromeDriverManager

load_dotenv()


def is_valid_url(url):
    """–ü–µ—Ä–µ–≤—ñ—Ä—è—î —á–∏ —î URL –∫–æ—Ä–µ–∫—Ç–Ω–∏–º"""
    try:
        if not url or not isinstance(url, str):
            return False
        url = url.strip()
        if not url:
            return False
        result = urlparse(url)
        return all([result.scheme, result.netloc]) and result.scheme in ['http', 'https']
    except:
        return False


def safe_navigate_to_url(driver, url, max_retries=3):
    """–ë–µ–∑–ø–µ—á–Ω–∞ –Ω–∞–≤—ñ–≥–∞—Ü—ñ—è –¥–æ URL –∑ –æ–±—Ä–æ–±–∫–æ—é –ø–æ–º–∏–ª–æ–∫"""
    if not url:
        print("‚ùå –ü–æ—Ä–æ–∂–Ω—ñ–π URL")
        return False

    url = url.strip()

    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –≤–∞–ª—ñ–¥–Ω—ñ—Å—Ç—å URL
    if not is_valid_url(url):
        print(f"‚ùå –ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π URL: {url}")
        return False

    for attempt in range(max_retries):
        try:
            print(f"üîÑ –°–ø—Ä–æ–±–∞ {attempt + 1}/{max_retries} - –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è URL: {url}")
            driver.get(url)
            WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.TAG_NAME, "body")))
            print(f"‚úÖ –£—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: {url}")
            return True

        except WebDriverException as e:
            error_msg = str(e).lower()
            print(f"‚ö†Ô∏è WebDriver –ø–æ–º–∏–ª–∫–∞ (—Å–ø—Ä–æ–±–∞ {attempt + 1}): {error_msg}")

            if "unsupported protocol" in error_msg:
                print(f"‚ùå –ù–µ–≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª –≤ URL: {url}")
                return False
            elif "invalid argument" in error_msg or "invalid url" in error_msg:
                print(f"‚ùå –ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π –∞—Ä–≥—É–º–µ–Ω—Ç URL: {url}")
                return False

            if attempt < max_retries - 1:
                print(f"‚è≥ –û—á—ñ–∫—É–≤–∞–Ω–Ω—è –ø–µ—Ä–µ–¥ –Ω–∞—Å—Ç—É–ø–Ω–æ—é —Å–ø—Ä–æ–±–æ—é...")
                time.sleep(2 * (attempt + 1))
            else:
                print(f"‚ùå –í—Å—ñ —Å–ø—Ä–æ–±–∏ –≤–∏—á–µ—Ä–ø–∞–Ω–æ –¥–ª—è URL: {url}")

        except TimeoutException:
            print(f"‚è∞ –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ URL: {url}")
            if attempt < max_retries - 1:
                time.sleep(2)

        except Exception as e:
            print(f"‚ùå –ù–µ—Å–ø–æ–¥—ñ–≤–∞–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {str(e)}")
            return False

    return False


session = requests.Session()
retries = Retry(
    total=5,
    backoff_factor=1,
    status_forcelist=[500, 502, 503, 504],
)
session.mount("https://", HTTPAdapter(max_retries=retries))

chrome_options = Options()
chrome_options.add_argument(
    "user-agent=Mozilla/5.0 (Windows NT 010.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
)
service = Service(ChromeDriverManager().install())
driver = webdriver.Chrome(service=service, options=chrome_options)

base_dir = "honeytoon"
os.makedirs(base_dir, exist_ok=True)

comics_data = []
failed_urls = []  # –î–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –Ω–µ–≤–¥–∞–ª–∏—Ö URL

try:
    honeytoon_email = os.getenv("HONEYTOON_EMAIL")
    honeytoon_password = os.getenv("HONEYTOON_PASSWORD")

    # Login
    login_url = f"https://honeytoon.com/?email={honeytoon_email}&modal=sign-in"
    if not safe_navigate_to_url(driver, login_url):
        raise Exception("–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å—Ç–æ—Ä—ñ–Ω–∫—É –ª–æ–≥—ñ–Ω—É")

    password_field = WebDriverWait(driver, 15).until(
        EC.element_to_be_clickable((By.CSS_SELECTOR, "input.form-control.password"))
    )
    ActionChains(driver).move_to_element(password_field).perform()
    time.sleep(random.uniform(1, 3))

    for char in honeytoon_password:
        password_field.send_keys(char)
        time.sleep(random.uniform(0.2, 0.5))

    password_field.send_keys(Keys.RETURN)
    time.sleep(random.uniform(3, 5))

    with open(os.path.join(base_dir, "honeytoon_link_comics.txt"), "r", encoding="utf-8") as file:
        links = file.readlines()
        for link_index, link in enumerate(links, 1):
            link = link.strip()
            print(f"\nüìñ –û–±—Ä–æ–±–∫–∞ –∫–æ–º—ñ–∫—Å—É {link_index}/{len(links)}: {link}")

            if not safe_navigate_to_url(driver, link):
                print(f"‚ùå –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –∫–æ–º—ñ–∫—Å —á–µ—Ä–µ–∑ –ø–æ–º–∏–ª–∫—É –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {link}")
                failed_urls.append({"type": "comic", "url": link, "reason": "Failed to load comic page"})
                continue

            try:
                comics = driver.find_elements(By.CLASS_NAME, "comic-book")
                if not comics:
                    print("‚ö†Ô∏è –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∫–æ–º—ñ–∫—Å—ñ–≤ –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ")
                    continue

                for comic_index, comic in enumerate(comics, 1):
                    try:
                        original_title = comic.find_element(By.CLASS_NAME, "comic-book__title").text.strip()
                        print(f"üé≠ –û–±—Ä–æ–±–∫–∞ –∫–æ–º—ñ–∫—Å—É: {original_title}")

                        # Format the title
                        display_title = original_title.replace("'", "")
                        display_title = ' '.join(word.capitalize() for word in display_title.split())

                        description = comic.find_element(By.CLASS_NAME, "comic-book__desc").text.strip()
                        genres = [genre.text.strip() for genre in
                                  comic.find_elements(By.CSS_SELECTOR, ".comic-book__labels .label__item")]
                        tags = [tag.text.strip() for tag in
                                comic.find_elements(By.CSS_SELECTOR, ".tags-wrapper .comic-tag")]
                        main_image = comic.find_element(By.CSS_SELECTOR, ".comic-book-img img").get_attribute("src")

                        # Clean directory name
                        dir_name = display_title
                        comic_dir = os.path.join(base_dir, dir_name)
                        os.makedirs(comic_dir, exist_ok=True)

                        # Create the comic data structure
                        comic_data = {
                            "title": display_title,
                            "originalTitle": original_title.upper(),
                            "description": description,
                            "thumbnail": "thumbnail.jpg",
                            "thumbnailBackground": "",
                            "previewThumbnail": "preview-thumbnail.jpg",
                            "genres": genres,
                            "tags": tags,
                            "episodes": []
                        }

                        # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ –∫–æ–º—ñ–∫—Å
                        with open(os.path.join(comic_dir, "info.txt"), "w", encoding="utf-8") as file:
                            file.write(f"title: {display_title}\n")
                            file.write(f"original title: {original_title.upper()}\n")
                            file.write(f"description: {description}\n")
                            file.write(f"genres: {', '.join(genres) if genres else 'No genres found'}\n")
                            file.write(f"tags: {', '.join(tags) if tags else 'No tags found'}\n")

                        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è thumbnail
                        try:
                            image_path = os.path.join(comic_dir, "thumbnail.jpg")
                            response = session.get(main_image, stream=True, verify=False)
                            if response.status_code == 200:
                                with open(image_path, "wb") as img_file:
                                    for chunk in response.iter_content(1024):
                                        img_file.write(chunk)
                        except Exception as e:
                            print(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ thumbnail: {e}")

                        # –ü–æ—à—É–∫ preview thumbnail
                        try:
                            search_field = WebDriverWait(driver, 20).until(
                                EC.presence_of_element_located((By.ID, "autoComplete"))
                            )

                            search_field.clear()
                            search_field.send_keys(original_title)
                            time.sleep(2)

                            search_result = WebDriverWait(driver, 20).until(
                                EC.presence_of_element_located((By.ID, "autoComplete_result_0"))
                            )
                            preview_image = search_result.find_element(By.TAG_NAME, "img").get_attribute("src")
                            preview_image_path = os.path.join(comic_dir, "preview-thumbnail.jpg")
                            response = requests.get(preview_image, stream=True)
                            if response.status_code == 200:
                                with open(preview_image_path, "wb") as img_file:
                                    for chunk in response.iter_content(1024):
                                        img_file.write(chunk)
                        except Exception as e:
                            print(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ preview thumbnail: {e}")

                        # –ó–±—ñ—Ä –ø–æ—Å–∏–ª–∞–Ω—å –Ω–∞ –µ–ø—ñ–∑–æ–¥–∏
                        links_file_path = os.path.join(comic_dir, "links_episode.txt")
                        episode_thumbnails = {}

                        try:
                            with open(links_file_path, "w", encoding="utf-8") as links_file:
                                comic_list = driver.find_element(By.CSS_SELECTOR,
                                                                 "body > main > section.section.comic-list .comic-list-items")
                                episodes = comic_list.find_elements(By.CLASS_NAME, "comic-list__item")

                                for index, episode in enumerate(episodes, start=1):
                                    link = episode.get_attribute("href")
                                    if link and is_valid_url(link):
                                        try:
                                            image = episode.find_element(By.CSS_SELECTOR,
                                                                         ".comic-list__img img").get_attribute("src")
                                            episode_thumbnails[link] = image
                                        except:
                                            print(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–Ω–∞–π—Ç–∏ thumbnail –¥–ª—è –µ–ø—ñ–∑–æ–¥—É {index}")
                                        links_file.write(f"{link}\n")
                                    else:
                                        print(f"‚ö†Ô∏è –ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –µ–ø—ñ–∑–æ–¥ {index}: {link}")
                        except Exception as e:
                            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–±–æ—Ä—ñ –ø–æ—Å–∏–ª–∞–Ω—å –Ω–∞ –µ–ø—ñ–∑–æ–¥–∏: {e}")
                            continue

                        # –û–±—Ä–æ–±–∫–∞ –µ–ø—ñ–∑–æ–¥—ñ–≤
                        try:
                            with open(links_file_path, "r", encoding="utf-8") as links_file:
                                episode_links = links_file.readlines()
                                episode_counter = 1

                                for episode_index, episode_link in enumerate(episode_links, start=1):
                                    episode_link = episode_link.strip()

                                    print(f"üì∫ –û–±—Ä–æ–±–∫–∞ –µ–ø—ñ–∑–æ–¥—É {episode_index}/{len(episode_links)}")

                                    # –ë–µ–∑–ø–µ—á–Ω–∞ –Ω–∞–≤—ñ–≥–∞—Ü—ñ—è –¥–æ –µ–ø—ñ–∑–æ–¥—É
                                    if not safe_navigate_to_url(driver, episode_link):
                                        print(f"‚ùå –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –µ–ø—ñ–∑–æ–¥ —á–µ—Ä–µ–∑ –ø–æ–º–∏–ª–∫—É –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {episode_link}")
                                        failed_urls.append({
                                            "type": "episode",
                                            "url": episode_link,
                                            "comic": display_title,
                                            "reason": "Failed to load episode page"
                                        })
                                        continue

                                    try:
                                        time.sleep(5)

                                        header_title = driver.find_element(By.CLASS_NAME,
                                                                           "header-episode__title-number").text.strip()
                                        print(f"üìÑ –ó–∞–≥–æ–ª–æ–≤–æ–∫ –µ–ø—ñ–∑–æ–¥—É: {header_title}")

                                        # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –ø—Ä–æ–ª–æ–≥–∏
                                        if "prologue" in header_title.lower():
                                            print(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –ø—Ä–æ–ª–æ–≥: {header_title}")
                                            continue

                                        # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–∞–ø–∫—É –¥–ª—è –µ–ø—ñ–∑–æ–¥—É
                                        episode_dir = os.path.join(comic_dir, f"{episode_counter:03d}")
                                        os.makedirs(episode_dir, exist_ok=True)

                                        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ thumbnail –µ–ø—ñ–∑–æ–¥—É
                                        if episode_link in episode_thumbnails:
                                            try:
                                                image_path = os.path.join(episode_dir, "thumbnail.jpg")
                                                response = session.get(episode_thumbnails[episode_link], stream=True,
                                                                       verify=False)
                                                if response.status_code == 200:
                                                    with open(image_path, "wb") as img_file:
                                                        for chunk in response.iter_content(1024):
                                                            img_file.write(chunk)
                                            except Exception as e:
                                                print(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ thumbnail –µ–ø—ñ–∑–æ–¥—É: {e}")

                                        # –ü–æ—à—É–∫ –∑–æ–±—Ä–∞–∂–µ–Ω—å –µ–ø—ñ–∑–æ–¥—É
                                        try:
                                            single_inner = WebDriverWait(driver, 20).until(
                                                EC.presence_of_element_located((By.CLASS_NAME, "single-inner"))
                                            )

                                            images = single_inner.find_elements(By.TAG_NAME, "img")
                                            episode_images = []

                                            for index, image in enumerate(images):
                                                image_url = driver.execute_script(
                                                    "return arguments[0].currentSrc || arguments[0].src;", image)
                                                image_filename = f"episode_{episode_counter:03d}_{index + 1:03d}.jpg"
                                                episode_images.append(image_filename)

                                                try:
                                                    if image_url.startswith("data:image/"):
                                                        header, encoded = image_url.split(",", 1)
                                                        image_data = base64.b64decode(encoded)
                                                        image_path = os.path.join(episode_dir, image_filename)
                                                        with open(image_path, "wb") as img_file:
                                                            img_file.write(image_data)
                                                    else:
                                                        response = session.get(image_url, stream=True, verify=False)
                                                        if response.status_code == 200:
                                                            image_path = os.path.join(episode_dir, image_filename)
                                                            with open(image_path, "wb") as img_file:
                                                                for chunk in response.iter_content(1024):
                                                                    img_file.write(chunk)

                                                    print(f"Saved image: {image_path} (URL: {image_url})")
                                                except requests.exceptions.SSLError as e:
                                                    print(f"SSL error for URL {image_url}: {e}")
                                                except Exception as e:
                                                    print(f"Failed to save image from URL {image_url}: {e}")

                                            # Add episode data to comic_data structure
                                            episode_data = {
                                                "parentTitle": display_title,
                                                "title": f"episode {episode_counter:03d}",
                                                "slag": f"episode-{episode_counter:03d}",
                                                "date": "",
                                                "thumbnail": "thumbnail.jpg",
                                                "images": episode_images
                                            }
                                            comic_data["episodes"].append(episode_data)

                                            episode_counter += 1

                                        except Exception as e:
                                            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ –∑–æ–±—Ä–∞–∂–µ–Ω—å –µ–ø—ñ–∑–æ–¥—É: {e}")
                                            continue

                                    except Exception as e:
                                        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ –µ–ø—ñ–∑–æ–¥—É {episode_link}: {e}")
                                        failed_urls.append({
                                            "type": "episode",
                                            "url": episode_link,
                                            "comic": display_title,
                                            "reason": f"Episode processing error: {str(e)}"
                                        })
                                        continue

                        except Exception as e:
                            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —á–∏—Ç–∞–Ω–Ω—ñ —Ñ–∞–π–ª—É –∑ –µ–ø—ñ–∑–æ–¥–∞–º–∏: {e}")

                        # Add the comic data to the comics_data list
                        comics_data.append(comic_data)
                        print(f"‚úÖ –ö–æ–º—ñ–∫—Å '{display_title}' —É—Å–ø—ñ—à–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–æ")

                    except Exception as e:
                        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ –∫–æ–º—ñ–∫—Å—É: {e}")
                        continue

            except Exception as e:
                print(f"‚ùå –ó–∞–≥–∞–ª—å–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –∫–æ–º—ñ–∫—Å—ñ–≤: {e}")
                continue

    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    with open(os.path.join(base_dir, "stolen_taste.json"), "w", encoding="utf-8") as json_file:
        json.dump(comics_data, json_file, indent=2, ensure_ascii=False)

    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –Ω–µ–≤–¥–∞–ª–∏—Ö URL
    if failed_urls:
        with open(os.path.join(base_dir, "failed_urls.json"), "w", encoding="utf-8") as failed_file:
            json.dump(failed_urls, failed_file, indent=2, ensure_ascii=False)
        print(f"\n‚ö†Ô∏è {len(failed_urls)} URL –Ω–µ –≤–¥–∞–ª–æ—Å—è –æ–±—Ä–æ–±–∏—Ç–∏. –ó–±–µ—Ä–µ–∂–µ–Ω–æ –≤ failed_urls.json")

    print(f"\n‚úÖ –ü—Ä–æ–≥—Ä–∞–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û–±—Ä–æ–±–ª–µ–Ω–æ {len(comics_data)} –∫–æ–º—ñ–∫—Å—ñ–≤.")

except Exception as e:
    print(f"‚ùå –ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {e}")
finally:
    driver.quit()
    print("üîí –ë—Ä–∞—É–∑–µ—Ä –∑–∞–∫—Ä–∏—Ç–æ")